{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527b90ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HealthCare\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-10 20:09:15.628 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:15.634 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-06-10 20:09:15.636 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.471 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run d:\\HealthCare\\venv\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-10 20:09:16.471 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.471 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.477 No runtime found, using MemoryCacheStorageManager\n",
      "2025-06-10 20:09:16.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.486 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-10 20:09:16.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 221\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base_df, synthetic_df  \u001b[38;5;66;03m# Return full synthetic dataset\u001b[39;00m\n\u001b[0;32m    220\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model()\n\u001b[1;32m--> 221\u001b[0m base_df, synthetic_df \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# Remove the combined_df creation since we're not using it\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# if model is None or base_df.empty:\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m#     st.warning(\"‚ö†Ô∏è Missing essential resources (model/data). Please verify setup.\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    248\u001b[0m \n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# === SHAP Visualization Helper ===\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mst_shap\u001b[39m(plot, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import urllib.request\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import google.generativeai as genai\n",
    "import shap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit.components.v1 as components\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dotenv import load_dotenv\n",
    "from fpdf import FPDF\n",
    "from babel.numbers import format_currency  # for currency formatting\n",
    "\n",
    "# === Font Bootstrap Helpers ===\n",
    "FONT_DIR = \"fonts\"\n",
    "FONT_NAME = \"DejaVuSans.ttf\"\n",
    "FONT_PATH = os.path.join(FONT_DIR, FONT_NAME)\n",
    "\n",
    "# CORRECTED RAW_URL: use raw.githubusercontent.com instead of github.com/raw\n",
    "# Updated RAW_URL as the previous one was returning 404\n",
    "RAW_URL = \"https://github.com/dejavu-fonts/dejavu-fonts/raw/main/ttf/DejaVuSans.ttf\"\n",
    "\n",
    "\n",
    "def _is_valid_ttf(path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Quick sanity-check: TrueType files typically begin with 0x00010000 (uint32) or b'true'.\n",
    "    Returns True if the file exists and starts with a valid TTF header.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        return False\n",
    "    with open(path, \"rb\") as fh:\n",
    "        tag = fh.read(4)\n",
    "    return tag in (b\"\\x00\\x01\\x00\\x00\", b\"true\")\n",
    "\n",
    "\n",
    "def bootstrap_font() -> str:\n",
    "    \"\"\"\n",
    "    Ensure that FONT_PATH points to a valid DejaVuSans.ttf.\n",
    "    If missing or invalid, download from RAW_URL.\n",
    "    Raises RuntimeError if download/validation fails.\n",
    "    Returns the path to a valid TTF file.\n",
    "    \"\"\"\n",
    "    os.makedirs(FONT_DIR, exist_ok=True)\n",
    "\n",
    "    # If the file doesn‚Äôt exist or fails the header check, attempt to download\n",
    "    if not _is_valid_ttf(FONT_PATH):\n",
    "        try:\n",
    "            logging.info(\"Downloading DejaVuSans.ttf ‚Ä¶\")\n",
    "            urllib.request.urlretrieve(RAW_URL, FONT_PATH)\n",
    "        except Exception as download_exc:\n",
    "            raise RuntimeError(\n",
    "                f\"Font download failed ‚Üí {download_exc}\"\n",
    "            ) from download_exc\n",
    "\n",
    "        # Re-check after download\n",
    "        if not _is_valid_ttf(FONT_PATH):\n",
    "            raise RuntimeError(\"Downloaded file is not a valid TrueType font.\")\n",
    "\n",
    "    return FONT_PATH\n",
    "\n",
    "\n",
    "# === Generate PDF Report ===\n",
    "def generate_pdf_report(health_summary: str, ai_response: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a PDF report containing the provided health_summary and AI recommendations.\n",
    "    Uses DejaVuSans.ttf for Unicode support. Returns the path to the generated PDF file,\n",
    "    or an empty string if generation failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        font_path = bootstrap_font()\n",
    "    except Exception as font_boot_exc:\n",
    "        st.error(f\"‚ùå Unicode font bootstrap failed: {font_boot_exc}\")\n",
    "        return \"\"\n",
    "\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Add DejaVu font (Unicode-capable)\n",
    "    try:\n",
    "        pdf.add_font(\"DejaVu\", \"\", font_path, uni=True)\n",
    "        pdf.set_font(\"DejaVu\", size=12)\n",
    "    except Exception as font_exc:\n",
    "        st.warning(\n",
    "            f\"‚ö†Ô∏è Could not add DejaVu TTF font: {font_exc}\\nFalling back to Arial.\"\n",
    "        )\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "    # Title & Summary\n",
    "    pdf.multi_cell(0, 10, \"AI Healthcare Summary Report\", align=\"C\")\n",
    "    pdf.ln()\n",
    "    pdf.multi_cell(0, 10, health_summary.strip())\n",
    "    pdf.ln()\n",
    "\n",
    "    # Gemini Recommendations\n",
    "    try:\n",
    "        pdf.set_font(\"DejaVu\", \"B\", size=12)\n",
    "    except BaseException:\n",
    "        pdf.set_font(\"Arial\", \"B\", size=12)\n",
    "    pdf.cell(0, 10, \"Gemini's Treatment Recommendations:\", ln=True)\n",
    "\n",
    "    try:\n",
    "        pdf.set_font(\"DejaVu\", size=12)\n",
    "    except BaseException:\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.multi_cell(0, 10, ai_response.strip())\n",
    "\n",
    "    # Persist PDF with a unique filename\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    filename = os.path.join(\"data\", f\"health_report_{uuid.uuid4().hex}.pdf\")\n",
    "\n",
    "    pdf.output(filename)\n",
    "    return filename\n",
    "    unique_id = str(uuid.uuid4())\n",
    "    output_path = os.path.join(\"data\", f\"health_report_{unique_id}.pdf\")\n",
    "    try:\n",
    "        pdf.output(output_path)\n",
    "    except Exception as export_exc:\n",
    "        st.error(f\"‚ùå Unable to save PDF report: {export_exc}\")\n",
    "        return \"\"\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "# === Load API Key ===\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    st.error(\n",
    "        \"‚ùå Gemini API key not found. Please set GOOGLE_API_KEY in your .env file.\"\n",
    "    )\n",
    "    st.stop()\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# === Streamlit Setup ===\n",
    "st.set_page_config(\n",
    "    page_title=\"JakeAI Healthcare Advisor\", layout=\"wide\", page_icon=\"üß†\"\n",
    ")\n",
    "\n",
    "\n",
    "# === Currency Formatter ===\n",
    "def format_currency(amount, symbol):\n",
    "    abs_amt = abs(amount)\n",
    "    if symbol == \"‚Çπ\":\n",
    "        if abs_amt >= 1e7:\n",
    "            return f\"{symbol}{abs_amt / 1e7:.1f}Cr\"\n",
    "        elif abs_amt >= 1e5:\n",
    "            return f\"{symbol}{abs_amt / 1e5:.1f}L\"\n",
    "    elif abs_amt >= 1e9:\n",
    "        return f\"{symbol}{abs_amt / 1e9:.1f}B\"\n",
    "    elif abs_amt >= 1e6:\n",
    "        return f\"{symbol}{abs_amt / 1e6:.1f}M\"\n",
    "    elif abs_amt >= 1e3:\n",
    "        return f\"{symbol}{abs_amt / 1e3:.1f}K\"\n",
    "    return f\"{symbol}{amount:,}\"\n",
    "\n",
    "\n",
    "# === Load Model & Data ===\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model_path = os.path.join(\n",
    "        \"models\", \"logistic_regression_pipeline.pkl\"\n",
    "    )  # \"models/logistic_regression_pipeline.pkl\"\n",
    "    if not os.path.isfile(model_path):\n",
    "        st.error(f\"‚ùå Model not found at '{model_path}'.\")\n",
    "        return None\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    # 1) Load the \"real\" dataset\n",
    "    base_path = \"data/cleaned_blood_data.csv\"\n",
    "    base_df = pd.DataFrame()\n",
    "    if not os.path.isfile(base_path):\n",
    "        st.error(f\"‚ùå Base data missing at '{base_path}'.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    else:\n",
    "        base_df = pd.read_csv(base_path)\n",
    "\n",
    "    # 2) Load the synthetic dataset if present\n",
    "    synthetic_path = \"data/synthetic_patient_dataset.csv\"\n",
    "    synthetic_df = pd.DataFrame()\n",
    "\n",
    "    if os.path.isfile(synthetic_path):\n",
    "        try:\n",
    "            # Load synthetic data\n",
    "            synthetic_df = pd.read_csv(synthetic_path)\n",
    "\n",
    "            # Normalize column names to lowercase\n",
    "            synthetic_df.columns = synthetic_df.columns.str.lower()\n",
    "\n",
    "            # Don't filter by base_df columns - keep all synthetic columns\n",
    "            # Only filter if we need to combine datasets (which we're not\n",
    "            # using)\n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå Error loading synthetic data: {e}\")\n",
    "    else:\n",
    "        st.warning(\n",
    "            f\"‚ö†Ô∏è Synthetic data missing at '{synthetic_path}'. Using base data only.\"\n",
    "        )\n",
    "        synthetic_df = pd.DataFrame()\n",
    "\n",
    "    return base_df, synthetic_df  # Return full synthetic dataset\n",
    "\n",
    "\n",
    "model = load_model()\n",
    "base_df, synthetic_df = load_data()\n",
    "\n",
    "# Remove the combined_df creation since we're not using it\n",
    "# if model is None or base_df.empty:\n",
    "#     st.warning(\"‚ö†Ô∏è Missing essential resources (model/data). Please verify setup.\")\n",
    "#     st.stop()\n",
    "\n",
    "# Create combined dataset for visualizations\n",
    "# if synthetic_df.empty:\n",
    "#     combined_df = base_df.copy()\n",
    "# else:\n",
    "#     common_cols = base_df.columns.intersection(synthetic_df.columns)\n",
    "#     combined_df = pd.concat([\n",
    "#         base_df[common_cols],\n",
    "#         synthetic_df[common_cols]\n",
    "#     ], ignore_index=True)\n",
    "\n",
    "# if model is None or base_df.empty:\n",
    "#     st.warning(\"‚ö†Ô∏è Missing essential resources (model/data). Please verify setup.\")\n",
    "#     st.stop()\n",
    "\n",
    "# Prepare combined data\n",
    "# common_cols = base_df.columns\n",
    "# if not synthetic_df.empty:\n",
    "#     common_cols = common_cols.intersection(synthetic_df.columns)\n",
    "# combined_df = pd.concat([base_df[common_cols], synthetic_df.get(common_cols, pd.DataFrame())], ignore_index=True)\n",
    "\n",
    "\n",
    "# === SHAP Visualization Helper ===\n",
    "def st_shap(plot, height=None):\n",
    "    shap_html = f\"<head>{shap.getjs()}</head><body>{plot.html()}</body>\"\n",
    "    components.html(shap_html, height=height or 500, scrolling=True)\n",
    "\n",
    "\n",
    "# === Recommendation Mapping ===\n",
    "def generate_recommendation(pred_label: int) -> str:\n",
    "    return {\n",
    "        0: \"‚úÖ **Low Risk**\\nMaintain your current healthy lifestyle. Annual check-ups recommended.\",\n",
    "        1: \"‚ö†Ô∏è **Medium Risk**\\nIncrease physical activity, monitor diet. Schedule a medical consultation.\",\n",
    "        2: \"üö® **High Risk**\\nImmediate medical attention advised. Begin treatment under supervision.\",\n",
    "    }.get(pred_label, \"‚ùì No recommendation available.\")\n",
    "\n",
    "\n",
    "# === Sidebar Inputs ===\n",
    "st.sidebar.header(\"üìù Patient Profile\")\n",
    "frequency = st.sidebar.slider(\"üìÖ Visit Frequency (visits/year)\", 0, 50, 5)\n",
    "age = st.sidebar.number_input(\"üéÇ Age\", min_value=1, max_value=120, value=22)\n",
    "gender = st.sidebar.selectbox(\"üë• Gender\", [\"Male\", \"Female\", \"Other\"])\n",
    "blood_pressure = st.sidebar.slider(\"ü©∏ Blood Pressure (mmHg)\", 80, 200, 120)\n",
    "heart_rate = st.sidebar.slider(\"üíì Heart Rate (bpm)\", 40, 180, 80)\n",
    "cholesterol = st.sidebar.slider(\"üß™ Cholesterol (mg/dL)\", 100, 400, 200)\n",
    "hemoglobin = st.sidebar.slider(\n",
    "    \"ü©∫ Hemoglobin (g/dL)\", 8.0, 20.0, 14.0, step=0.1)\n",
    "smoking_status = st.sidebar.selectbox(\n",
    "    \"üö¨ Smoking Status\", [\"Non-smoker\", \"Smoker\"])\n",
    "exercise_level = st.sidebar.selectbox(\n",
    "    \"üèÉ Exercise Level\", [\n",
    "        \"Low\", \"Moderate\", \"High\"])\n",
    "\n",
    "# Currency and default ranges based on economic context\n",
    "currency_options = {\n",
    "    \"$\": {\"label\": \"USD\", \"min\": 1000, \"max\": 200000, \"step\": 1000},\n",
    "    \"‚Ç¨\": {\"label\": \"Euro\", \"min\": 1000, \"max\": 180000, \"step\": 1000},\n",
    "    \"‚Çπ\": {\"label\": \"INR\", \"min\": 5000, \"max\": 2000000, \"step\": 5000},\n",
    "    \"¬£\": {\"label\": \"GBP\", \"min\": 1000, \"max\": 150000, \"step\": 1000},\n",
    "    \"¬•\": {\"label\": \"JPY\", \"min\": 100000, \"max\": 10000000, \"step\": 100000},\n",
    "    \"‚Ç©\": {\"label\": \"KRW\", \"min\": 1000000, \"max\": 50000000, \"step\": 1000000},\n",
    "    \"‚ÇΩ\": {\"label\": \"RUB\", \"min\": 10000, \"max\": 2000000, \"step\": 10000},\n",
    "    \"‚Ç∫\": {\"label\": \"TRY\", \"min\": 1000, \"max\": 300000, \"step\": 1000},\n",
    "    \"AED\": {\"label\": \"Dirham\", \"min\": 2000, \"max\": 500000, \"step\": 2000},\n",
    "}\n",
    "\n",
    "# Sidebar currency selection\n",
    "currency_symbol = st.sidebar.selectbox(\n",
    "    \"üí± Choose Currency\", list(currency_options.keys())\n",
    ")\n",
    "currency_range = currency_options[currency_symbol]\n",
    "monetary = st.sidebar.slider(\n",
    "    f\"üí∏ Annual Healthcare Spending ({currency_symbol})\",\n",
    "    min_value=currency_range[\"min\"],\n",
    "    max_value=currency_range[\"max\"],\n",
    "    value=(currency_range[\"min\"] + currency_range[\"max\"]) // 2,\n",
    "    step=currency_range[\"step\"],\n",
    ")\n",
    "\n",
    "try:\n",
    "    formatted_spending = format_currency(monetary, currency_symbol)\n",
    "except BaseException:\n",
    "    formatted_spending = f\"{currency_symbol}{monetary}\"\n",
    "\n",
    "time = st.sidebar.slider(\"‚è≥ Time Since Last Visit (months)\", 0, 60, 12)\n",
    "formatted_spending = format_currency(monetary, currency_symbol)\n",
    "\n",
    "# === Main Page ===\n",
    "st.title(\"üß† Jake-Driven Personalized Healthcare Advisor\")\n",
    "st.markdown(\"Empowering health decisions through machine intelligence.\")\n",
    "\n",
    "# === Tabs ===\n",
    "tab1, tab2, tab3, tab4, tab5 = st.tabs(\n",
    "    [\n",
    "        \"üß¨ Recommendation Engine\",\n",
    "        \"üìä Data Intelligence\",\n",
    "        \"üîç Model Insights\",\n",
    "        \"ü§ñ AI Chat Assistant\",\n",
    "        \"‚ÑπÔ∏è About\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# === Tab 1: Recommendation Engine ===\n",
    "with tab1:\n",
    "    st.subheader(\"Your Personalized Health Recommendation\")\n",
    "\n",
    "    # Upload patient dataset for batch prediction\n",
    "    uploaded_file = st.file_uploader(\n",
    "        \"üìÅ Upload a file for processing (CSV/TXT/PDF/DOCX)\", type=None\n",
    "    )\n",
    "\n",
    "    if uploaded_file:\n",
    "        file_ext = os.path.splitext(uploaded_file.name)[1].lower()\n",
    "\n",
    "        try:\n",
    "            if file_ext == \".csv\":\n",
    "                batch_data = pd.read_csv(uploaded_file)\n",
    "                st.success(\"‚úÖ CSV file uploaded successfully.\")\n",
    "\n",
    "                # Check if required columns exist\n",
    "                required_cols = [\"Frequency\", \"Monetary\", \"Time\"]\n",
    "                if all(col in batch_data.columns for col in required_cols):\n",
    "                    batch_data[\"Prediction\"] = model.predict(\n",
    "                        batch_data[required_cols])\n",
    "                    st.success(\"‚úÖ CSV processed.\")\n",
    "                    st.dataframe(batch_data)\n",
    "                    st.download_button(\n",
    "                        \"üì• Download Predictions\",\n",
    "                        batch_data.to_csv(index=False),\n",
    "                        \"batch_predictions.csv\",\n",
    "                        mime=\"text/csv\",\n",
    "                    )\n",
    "                else:\n",
    "                    missing = [\n",
    "                        col for col in required_cols if col not in batch_data.columns\n",
    "                    ]\n",
    "                    st.error(\n",
    "                        f\"‚ùå Missing required columns: {', '.join(missing)}\")\n",
    "\n",
    "            elif file_ext in [\".txt\", \".md\"]:\n",
    "                content = uploaded_file.read().decode(\"utf-8\")\n",
    "                st.text_area(\"üìÑ File Content\", content, height=300)\n",
    "            elif file_ext == \".pdf\":\n",
    "                reader = PdfReader(uploaded_file)\n",
    "                text = \"\".join(\n",
    "                    [page.extract_text() or \"\" for page in reader.pages])\n",
    "                st.text_area(\n",
    "                    \"üìë Extracted PDF Text\", text or \"No text found.\", height=300\n",
    "                )\n",
    "\n",
    "            elif file_ext == \".docx\":\n",
    "                doc = Document(uploaded_file)\n",
    "                doc_text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "                st.text_area(\"üìù Word Document Content\", doc_text, height=300)\n",
    "\n",
    "            else:\n",
    "                st.warning(\n",
    "                    f\"‚ö†Ô∏è File type '{file_ext}' not supported for processing. \"\n",
    "                    \"Please upload a supported format.\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå Word document processing failed: {e}\")\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     st.error(f\"‚ùå PDF extraction failed: {e}\")\n",
    "\n",
    "    # Individual Recommendation\n",
    "    if st.sidebar.button(\"üí° Generate Recommendation\"):\n",
    "        # 1) Build DataFrame for prediction\n",
    "        input_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Frequency\": [frequency],\n",
    "                \"Monetary\": [monetary],\n",
    "                \"Time\": [time],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 2) Predict\n",
    "        try:\n",
    "            prediction = model.predict(input_df)[0]\n",
    "            probs = model.predict_proba(input_df)[0]\n",
    "            confidence = f\"{probs[prediction] * 100:.2f}%\"\n",
    "            recommendation = generate_recommendation(prediction)\n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå Model prediction failed: {e}\")\n",
    "            st.stop()\n",
    "\n",
    "        # 3) Build health summary\n",
    "        rec_clean = (\n",
    "            str(recommendation)\n",
    "            .replace(\"**\", \"\")\n",
    "            .replace(\"‚úÖ\", \"\")\n",
    "            .replace(\"‚ö†Ô∏è\", \"\")\n",
    "            .replace(\"üö®\", \"\")\n",
    "        )\n",
    "        health_summary = (\n",
    "            \"Patient Health Summary:\\n\"\n",
    "            f\"- Risk Level: {['Low', 'Medium', 'High'][prediction]}\\n\"\n",
    "            f\"- Confidence: {confidence}\\n\"\n",
    "            f\"- Recommendation: {rec_clean}\\n\"\n",
    "            f\"- Visit Frequency: {frequency}\\n\"\n",
    "            f\"- Healthcare Spending: {format_currency(monetary, currency_symbol)}\\n\"\n",
    "            f\"- Time Since Last Visit: {time} months\\n\"\n",
    "        )\n",
    "        st.session_state[\"health_summary\"] = health_summary\n",
    "\n",
    "        # 4) Gemini AI Treatment Suggestion\n",
    "        with st.spinner(\"üî¨ Analyzing treatment options using Jake...\"):\n",
    "            try:\n",
    "                chat_model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "                chat = chat_model.start_chat(history=[])\n",
    "                prompt = (\n",
    "                    f\"{health_summary.strip()}\\n\\n\"\n",
    "                    \"Based on the patient's complete profile and identified health risks, provide the following details:\\n\"\n",
    "                    \"1. Likely cause(s) of the health risk.\\n\"\n",
    "                    \"2. Recommended lifestyle, dietary, or behavioral changes.\\n\"\n",
    "                    \"3. A detailed and specific treatment plan tailored to the condition.\\n\"\n",
    "                    \"4. Exact **medication names (generic or brand)** that are commonly prescribed for this condition globally,\\n\"\n",
    "                    \"   including the dosage form (e.g., tablet, capsule, injection), standard dosage range (if available),\\n\"\n",
    "                    \"   and any important administration guidelines.\\n\"\n",
    "                    \"5. Specialist doctor recommendations (if any).\\n\"\n",
    "                    \"6. Rationale behind the treatment and medicine choice.\\n\"\n",
    "                    \"7. Include warnings or contraindications for the mentioned medications.\\n\\n\"\n",
    "                    \"Only suggest medicines that are clinically approved and widely used. If no medicine is applicable, state clearly.\"\n",
    "                )\n",
    "                ai_response = chat.send_message(prompt)\n",
    "                response_text = ai_response.text or \"\"\n",
    "                st.markdown(\"### üß† Jake's Auto Analysis\")\n",
    "                st.success(\"‚úÖ Jake's AI-driven treatment suggestions:\")\n",
    "                try:\n",
    "                    st.markdown(response_text)\n",
    "                except Exception:\n",
    "                    st.code(response_text)\n",
    "\n",
    "                    st.warning(\n",
    "                        \"‚ö†Ô∏è Disclaimer: This is an AI-generated suggestion. Always consult a certified medical professional before starting any medication.\"\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                st.error(\"‚ùå Jake AI failed to process the treatment plan.\")\n",
    "                st.exception(e)\n",
    "                response_text = \"\"\n",
    "\n",
    "        # 5) PDF Export\n",
    "        if response_text:\n",
    "            pdf_file = generate_pdf_report(health_summary, response_text)\n",
    "            if pdf_file and os.path.isfile(pdf_file):\n",
    "                with open(pdf_file, \"rb\") as f:\n",
    "                    st.download_button(\n",
    "                        label=\"üìÑ Download Full PDF Report\",\n",
    "                        data=f,\n",
    "                        file_name=os.path.basename(pdf_file),\n",
    "                        mime=\"application/pdf\",\n",
    "                    )\n",
    "\n",
    "            st.download_button(\n",
    "                label=\"üì• Download Treatment Plan\",\n",
    "                data=response_text,\n",
    "                file_name=\"treatment_plan.txt\",\n",
    "                mime=\"text/plain\",\n",
    "            )\n",
    "\n",
    "        # 6) Visualizations\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col1:\n",
    "            st.metric(\n",
    "                \"Predicted Risk Level\", [\n",
    "                    \"Low\", \"Medium\", \"High\"][prediction])\n",
    "            st.metric(\"Prediction Confidence\", confidence)\n",
    "            st.markdown(recommendation)\n",
    "\n",
    "            # Feature Importance\n",
    "            try:\n",
    "                classifier_step = next(\n",
    "                    step\n",
    "                    for step in model.named_steps\n",
    "                    if hasattr(model.named_steps[step], \"coef_\")\n",
    "                )\n",
    "                classifier = model.named_steps[classifier_step]\n",
    "                importance = classifier.coef_[0]\n",
    "            except Exception:\n",
    "                importance = [0, 0, 0]\n",
    "\n",
    "            fig_imp = px.bar(\n",
    "                x=[\"Frequency\", \"Monetary\", \"Time\"],\n",
    "                y=importance,\n",
    "                labels={\"x\": \"Features\", \"y\": \"Importance\"},\n",
    "                title=\"Feature Contribution to Risk\",\n",
    "            )\n",
    "            st.plotly_chart(fig_imp, use_container_width=True)\n",
    "\n",
    "            # === SHAP Explainability (dynamic step detection with diagnostics & proper background) ===\n",
    "            st.markdown(\"#### üß† Model Explainability (SHAP)\")\n",
    "            with st.expander(\"Show SHAP values\"):\n",
    "                try:\n",
    "                    # 1) Identify classifier and preprocessor from pipeline\n",
    "                    if isinstance(model, Pipeline):\n",
    "                        classifier = model.steps[-1][1]\n",
    "                        preprocessor = Pipeline(model.steps[:-1]) if len(model.steps) > 1 else None\n",
    "                    else:\n",
    "                        if hasattr(model, \"predict_proba\"):\n",
    "                            classifier, preprocessor = model, None\n",
    "                        else:\n",
    "                            raise ValueError(\"Model is not a Pipeline and has no predict_proba.\")\n",
    "\n",
    "                    if not hasattr(classifier, \"predict_proba\"):\n",
    "                        raise ValueError(\"Detected classifier has no predict_proba method.\")\n",
    "\n",
    "                    # 2) Inspect input_df\n",
    "                    st.write(\"üîç input_df shape:\", input_df.shape)\n",
    "                    st.write(\"üîç input_df columns:\", input_df.columns.tolist())\n",
    "\n",
    "                    # Transform the single-row input\n",
    "                    if preprocessor is not None:\n",
    "                        X_pre = preprocessor.transform(input_df)\n",
    "                        st.write(\"üîç Transformed input X_pre shape:\", X_pre.shape)\n",
    "                    else:\n",
    "                        X_pre = input_df.values\n",
    "                        st.write(\"üîç Raw input array X_pre shape:\", X_pre.shape)\n",
    "\n",
    "                    if X_pre.ndim != 2:\n",
    "                        raise ValueError(f\"Expected transformed input to be 2D, but got shape: {X_pre.shape}\")\n",
    "\n",
    "                    # 3) Prepare background from training data (base_df)\n",
    "                    if \"base_df\" in globals() and not base_df.empty:\n",
    "                    # sample up to 100 rows\n",
    "                        bg_df = base_df[input_df.columns].sample(n=min(100, len(base_df)), random_state=42)\n",
    "                        if preprocessor is not None:\n",
    "                            background = preprocessor.transform(bg_df)\n",
    "                        else:\n",
    "                            background = bg_df.values\n",
    "                        st.write(\"üîç Background after transform shape:\", background.shape)\n",
    "                    else:\n",
    "                        raise ValueError(\"base_df is missing or empty; please supply a proper background dataset for SHAP.\")\n",
    "\n",
    "                    if background.ndim != 2:\n",
    "                        raise ValueError(f\"Expected background array to be 2D, but got shape: {background.shape}\")\n",
    "\n",
    "                    # 4) Create explainer & 5) compute SHAP values\n",
    "                    explainer = shap.KernelExplainer(classifier.predict_proba, background)\n",
    "                    shap_vals = explainer.shap_values(X_pre, nsamples=100)\n",
    "\n",
    "                    # 6) Pick the right class slice\n",
    "                    if isinstance(shap_vals, list):\n",
    "                    # binary or multiclass\n",
    "                        if len(shap_vals) == 2:\n",
    "                            shap_array = shap_vals[1]\n",
    "                            st.write(\"üîç Explaining positive-class SHAP values (index 1)\")\n",
    "                        else:\n",
    "                            idx = int(classifier.predict(X_pre)[0])\n",
    "                            shap_array = shap_vals[idx]\n",
    "                            st.write(f\"üîç Explaining class index {idx} SHAP values\")\n",
    "                    elif isinstance(shap_vals, np.ndarray):\n",
    "                        if shap_vals.ndim == 2:\n",
    "                            shap_array = shap_vals\n",
    "                            st.write(\"üîç shap_vals is 2D ndarray, using directly\")\n",
    "                        elif shap_vals.ndim == 3:\n",
    "                            n_s, n_f, n_c = shap_vals.shape\n",
    "                            if n_c == 2:\n",
    "                                shap_array = shap_vals[:, :, 1]\n",
    "                                st.write(\"üîç shap_vals is 3D ndarray, picking positive-class axis=2 index 1\")\n",
    "                            else:\n",
    "                                idx = int(classifier.predict(X_pre)[0])\n",
    "                                shap_array = shap_vals[:, :, idx]\n",
    "                                st.write(f\"üîç shap_vals is 3D ndarray, picking predicted-class index {idx}\")\n",
    "                        else:\n",
    "                            raise ValueError(f\"Unexpected shap_vals ndarray ndim={shap_vals.ndim}\")\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected shap_vals type: {type(shap_vals)}\")\n",
    "\n",
    "                    st.write(\"üîç shap_array shape:\", shap_array.shape)\n",
    "                    if shap_array.ndim != 2:\n",
    "                        raise ValueError(f\"Expected shap_array to be 2D, but got: {shap_array.shape}\")\n",
    "\n",
    "                    # 7) Uniformity / plotting\n",
    "                    n_samples, n_features = shap_array.shape\n",
    "                    feature_names = input_df.columns.tolist()\n",
    "\n",
    "                    if n_samples > 1:\n",
    "            # multiple inputs ‚Üí compare rows\n",
    "                        if np.allclose(shap_array, shap_array[0], atol=1e-8):\n",
    "                            st.info(\"‚ÑπÔ∏è SHAP values are uniform across the samples ‚Äî no variation in feature influence.\")\n",
    "                            st.dataframe(pd.DataFrame(shap_array, columns=feature_names))\n",
    "                        else:\n",
    "                            fig, ax = plt.subplots()\n",
    "                            shap.summary_plot(\n",
    "                            shap_array,\n",
    "                            features=X_pre,\n",
    "                            feature_names=feature_names,\n",
    "                            plot_type=\"bar\",\n",
    "                            show=False,\n",
    "                            alpha=0.8\n",
    "                        )\n",
    "                        ax.set_title(\"SHAP Feature Contribution\")\n",
    "                        st.pyplot(fig)\n",
    "\n",
    "                    else:\n",
    "                        # single input ‚Üí compare feature values\n",
    "                        row = shap_array[0]\n",
    "                        if np.allclose(row, np.full_like(row, row[0]), atol=1e-8):\n",
    "                            st.info(\"‚ÑπÔ∏è SHAP values for all features are nearly identical for this input.\")\n",
    "                            st.dataframe(pd.DataFrame([row], columns=feature_names))\n",
    "                        else:\n",
    "                            fig, ax = plt.subplots()\n",
    "                            shap.summary_plot(\n",
    "                            row.reshape(1, -1),\n",
    "                            features=X_pre,\n",
    "                            feature_names=feature_names,\n",
    "                            plot_type=\"bar\",\n",
    "                            show=False,\n",
    "                            alpha=0.8\n",
    "                        )\n",
    "                        ax.set_title(\"SHAP Feature Contribution\")\n",
    "                        st.pyplot(fig)\n",
    "\n",
    "                except Exception as e:\n",
    "                    st.warning(f\"‚ö†Ô∏è SHAP could not be generated: {e}\")\n",
    "\n",
    "\n",
    "        with col2:\n",
    "            st.markdown(\"#### üìä Your Health Snapshot\")\n",
    "            patient_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"Metric\": [\n",
    "                        \"Visit Frequency\",\n",
    "                        f\"Spending ({currency_symbol})\",\n",
    "                        \"Time Since Last Visit\",\n",
    "                    ],\n",
    "                    \"Value\": [frequency, monetary, time],\n",
    "                }\n",
    "            )\n",
    "            avg = [\n",
    "                base_df[\"Frequency\"].mean(),\n",
    "                base_df[\"Monetary\"].mean(),\n",
    "                base_df[\"Time\"].mean(),\n",
    "            ]\n",
    "\n",
    "            fig_patient = go.Figure()\n",
    "            fig_patient.add_trace(\n",
    "                go.Bar(\n",
    "                    x=patient_df[\"Metric\"],\n",
    "                    y=patient_df[\"Value\"],\n",
    "                    name=\"You\")\n",
    "            )\n",
    "            fig_patient.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=patient_df[\"Metric\"],\n",
    "                    y=avg,\n",
    "                    mode=\"lines+markers\",\n",
    "                    name=\"Population Avg\",\n",
    "                )\n",
    "            )\n",
    "            fig_patient.update_layout(\n",
    "                title=\"Your Metrics vs Population Average\")\n",
    "            st.plotly_chart(fig_patient, use_container_width=True)\n",
    "\n",
    "    else:\n",
    "        st.info(\"üëà Adjust sidebar inputs and click 'Generate Recommendation'.\")\n",
    "\n",
    "# === Tab 2: Data Intelligence ===\n",
    "with tab2:\n",
    "    st.subheader(\"üìÇ Dataset Overview\")\n",
    "\n",
    "    # === üîπ ROW 1: Dataset Preview + Risk Class ===\n",
    "    st.markdown(\"### üîç Data Snapshot\")\n",
    "    row1_col1, row1_col2 = st.columns([1.5, 1])  # Wider data table\n",
    "\n",
    "    with row1_col1:\n",
    "        st.markdown(\"#### üßæ Sample Data\")\n",
    "        st.dataframe(base_df.head(), use_container_width=True)\n",
    "\n",
    "        st.markdown(\"#### üìä Summary Statistics\")\n",
    "        st.dataframe(base_df.describe(), use_container_width=True)\n",
    "\n",
    "        st.markdown(\"#### üß¨ Dataset Fields\")\n",
    "        st.markdown(\"\"\"\n",
    "        - Hemoglobin | Blood Pressure | Heart Rate\n",
    "        - Cholesterol | White Blood Cell Count | Glucose\n",
    "        - Gender | Age | Smoking Status\n",
    "        - Exercise Level | BMI | Blood Type\n",
    "        \"\"\")\n",
    "\n",
    "    with row1_col2:\n",
    "        st.markdown(\"#### ü©∫ Risk Class Distribution\")\n",
    "        if \"Class\" in base_df.columns:\n",
    "            fig_class = px.pie(\n",
    "                base_df, names=\"Class\", title=\"Risk Class Distribution\", hole=0.3\n",
    "            )\n",
    "            fig_class.update_layout(height=300)\n",
    "            st.plotly_chart(fig_class, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"‚ö†Ô∏è 'Class' column not available\")\n",
    "        st.markdown(\"\")\n",
    "\n",
    "    st.divider()\n",
    "\n",
    "    # === üîπ ROW 2: Synthetic Gender & Diabetes ===\n",
    "    st.markdown(\"### üß† Synthetic Data Insights\")\n",
    "    row2_col1, row2_col2 = st.columns(2)\n",
    "\n",
    "    with row2_col1:\n",
    "        st.markdown(\"#### üë• Gender Distribution\")\n",
    "        if synthetic_df.empty:\n",
    "            st.warning(\"‚ö†Ô∏è Synthetic dataset is empty.\")\n",
    "        elif \"gender\" not in synthetic_df.columns:\n",
    "            st.warning(\"‚ö†Ô∏è 'gender' column not found.\")\n",
    "            st.code(synthetic_df.columns.tolist())\n",
    "        else:\n",
    "            synthetic_df[\"gender_label\"] = synthetic_df[\"gender\"].apply(\n",
    "                lambda x: \"Male\" if x >= 0.5 else \"Female\"\n",
    "            )\n",
    "            gender_counts = synthetic_df[\"gender_label\"].value_counts()\n",
    "\n",
    "            if not gender_counts.empty:\n",
    "                fig_gender = px.pie(\n",
    "                    base_df,\n",
    "                    names=gender_counts.index,\n",
    "                    values=gender_counts.values,\n",
    "                    title=\"Gender Distribution\",\n",
    "                    hole=0.3,\n",
    "                )\n",
    "                fig_gender.update_layout(height=300)\n",
    "                st.plotly_chart(fig_gender, use_container_width=True)\n",
    "            else:\n",
    "                st.warning(\"‚ö†Ô∏è No gender data after processing\")\n",
    "            st.markdown(\"**üî¢ Gender Summary**\")\n",
    "            st.dataframe(\n",
    "                synthetic_df[\"gender\"].describe().to_frame(), use_container_width=True\n",
    "            )\n",
    "\n",
    "    with row2_col2:\n",
    "        st.markdown(\"#### üß™ Diabetes Distribution\")\n",
    "        if synthetic_df.empty:\n",
    "            st.warning(\"‚ö†Ô∏è Synthetic dataset is empty.\")\n",
    "        elif \"diabetes\" not in synthetic_df.columns:\n",
    "            st.warning(\"‚ö†Ô∏è 'diabetes' column not found.\")\n",
    "            st.code(synthetic_df.columns.tolist())\n",
    "        else:\n",
    "            synthetic_df[\"diabetes_label\"] = synthetic_df[\"diabetes\"].apply(\n",
    "                lambda x: \"Diabetic\" if x >= 1.5 else \"Non-Diabetic\"\n",
    "            )\n",
    "            diabetes_counts = synthetic_df[\"diabetes_label\"].value_counts()\n",
    "\n",
    "            if not diabetes_counts.empty:\n",
    "                fig_diabetes = px.pie(\n",
    "                    names=diabetes_counts.index,\n",
    "                    values=diabetes_counts.values,\n",
    "                    title=\"Diabetes Distribution\",\n",
    "                    hole=0.3,\n",
    "                )\n",
    "                fig_diabetes.update_layout(height=300)\n",
    "                st.plotly_chart(fig_diabetes, use_container_width=True)\n",
    "            else:\n",
    "                st.warning(\"‚ö†Ô∏è No diabetes data after processing\")\n",
    "\n",
    "            st.markdown(\"**üî¢ Diabetes Summary**\")\n",
    "            st.dataframe(\n",
    "                synthetic_df[\"diabetes\"].describe().to_frame(), use_container_width=True\n",
    "            )\n",
    "\n",
    "    # üîé Debug Info (optional toggle)\n",
    "    with st.expander(\"üõ†Ô∏è Synthetic Data Debug Info\"):\n",
    "        st.code(f\"Shape: {synthetic_df.shape}\")\n",
    "        st.code(f\"Columns: {synthetic_df.columns.tolist()}\")\n",
    "        if not synthetic_df.empty:\n",
    "            st.dataframe(synthetic_df.head(3), use_container_width=True)\n",
    "\n",
    "    # === üîπ ROW 3 : Time Since Last Visit ===\n",
    "    st.markdown(\"### üï∞Ô∏è Time Since Last Visit\")\n",
    "    row3_col1, row3_col2 = st.columns(2)\n",
    "\n",
    "    with row3_col1:\n",
    "        if \"Time\" in base_df.columns:\n",
    "            st.markdown(\"#### Time Since Last Visit Distribution\")\n",
    "            fig_time = px.histogram(\n",
    "                base_df, x=\"Time\", title=\"Time Since Last Visit (months)\", nbins=20\n",
    "            )\n",
    "            st.plotly_chart(fig_time, use_container_width=True)\n",
    "        else:\n",
    "            st.info(\"‚ö†Ô∏è 'Time' column not available for distribution plot.\")\n",
    "\n",
    "with tab3:\n",
    "    st.subheader(\"üìà Model Performance & Insights\")\n",
    "\n",
    "    # Load the dataset\n",
    "    base_df = pd.read_csv(\"./data/synthetic_patient_dataset.csv\")\n",
    "\n",
    "    # Normalize column names\n",
    "    base_df.columns = base_df.columns.str.lower()\n",
    "    if \"class\" in base_df.columns:\n",
    "        base_df.rename(columns={\"class\": \"diabetes\"}, inplace=True)\n",
    "\n",
    "    # 1Ô∏è‚É£ Correlation heatmap\n",
    "    corr = base_df.corr(numeric_only=True)\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    fig_corr, ax = plt.subplots(figsize=(20, 12))\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        fmt=\".3f\",\n",
    "        cmap=\"rocket_r\",\n",
    "        linewidths=0.5,\n",
    "        square=True,\n",
    "        cbar_kws={\"shrink\": 0.9},\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(\"Correlation Matrix of Health Features\", fontsize=16)\n",
    "\n",
    "    corr_masked = corr.where(~mask)  # upper-triangle ‚Üí NaN\n",
    "\n",
    "    # Build interactive Plotly heatmap\n",
    "    fig = px.imshow(\n",
    "        corr_masked,\n",
    "        text_auto=\".3f\",\n",
    "        # rocket_r\n",
    "        color_continuous_scale=px.colors.sequential.Inferno_r[::-1],\n",
    "        zmin=-1,\n",
    "        zmax=1,\n",
    "        labels=dict(x=\"\", y=\"\", color=\"corr\"),\n",
    "        width=1200,\n",
    "        height=700,\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Correlation Matrix of Health Features\",\n",
    "        xaxis_side=\"bottom\",\n",
    "        font=dict(size=12),\n",
    "        margin=dict(l=50, r=50, t=80, b=50),\n",
    "    )\n",
    "    # Rotate x-axis labels to match your style\n",
    "    fig.update_xaxes(tickangle=45, tickfont=dict(size=11))\n",
    "    fig.update_yaxes(tickfont=dict(size=11), autorange=\"reversed\")\n",
    "\n",
    "    # Show interactive figure\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # Optional: Download button for the heatmap\n",
    "    buf = BytesIO()\n",
    "    # generate the static one for PNG download\n",
    "    fig_static, ax = plt.subplots(figsize=(20, 12))\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        fmt=\".3f\",\n",
    "        cmap=\"rocket_r\",\n",
    "        linewidths=0.5,\n",
    "        square=True,\n",
    "        cbar_kws={\"shrink\": 0.9},\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(\"Correlation Matrix of Health Features\", fontsize=16)\n",
    "    fig_static.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "    st.download_button(\n",
    "        label=\"üì• Download Heatmap as PNG\",\n",
    "        data=buf.getvalue(),\n",
    "        file_name=\"correlation_heatmap.png\",\n",
    "        mime=\"image/png\",\n",
    "    )\n",
    "\n",
    "    # 2Ô∏è‚É£ Live Seaborn countplot for Gender vs Diabetes\n",
    "\n",
    "    # Load and preprocess data\n",
    "    base_df = pd.read_csv(\"./data/synthetic_patient_dataset.csv\")\n",
    "    base_df_o = pd.read_csv(\"./data/cleaned_blood_data.csv\")\n",
    "\n",
    "    # 1Ô∏è‚É£ Categorize gender (Assuming values near 0 = Female, 1 = Male)\n",
    "    base_df[\"gender_cat\"] = base_df[\"gender\"].apply(\n",
    "        lambda x: \"Male\" if x >= 0.5 else \"Female\"\n",
    "    )\n",
    "\n",
    "    # 2Ô∏è‚É£ Categorize diabetes (Assuming a threshold for diagnosis, e.g., >=1.5\n",
    "    # is diabetic)\n",
    "    base_df[\"diabetes_cat\"] = base_df[\"diabetes\"].apply(\n",
    "        lambda x: \"Diabetic\" if x >= 1.5 else \"Non-Diabetic\"\n",
    "    )\n",
    "\n",
    "    # 3Ô∏è‚É£ Count Plot for Gender vs Diabetes\n",
    "    st.markdown(\"#### üë• Gender Distribution by Diabetes Class\")\n",
    "\n",
    "    fig_gender, ax_gender = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    sns.countplot(\n",
    "        data=base_df,\n",
    "        x=\"gender_cat\",\n",
    "        hue=\"diabetes_cat\",\n",
    "        palette=sns.color_palette(\"Set2\", 2),\n",
    "        ax=ax_gender,\n",
    "    )\n",
    "\n",
    "    # Enhance visuals\n",
    "    ax_gender.set_xlabel(\"Gender\", fontsize=12)\n",
    "    ax_gender.set_ylabel(\"Count\", fontsize=12)\n",
    "    ax_gender.set_title(\"Diabetes Distribution by Gender\", fontsize=14)\n",
    "    ax_gender.legend(title=\"Diabetes\", title_fontsize=11, fontsize=10)\n",
    "    ax_gender.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Show the updated figure\n",
    "    st.pyplot(fig_gender)\n",
    "\n",
    "    # BMI vs Age colored by Diabetes\n",
    "    if all(c in base_df.columns for c in [\"age\", \"bmi\", \"diabetes\"]):\n",
    "        st.markdown(\"#### üìâ BMI vs Age by Diabetes Class\")\n",
    "        fig_bmi_age = px.scatter(\n",
    "            base_df,\n",
    "            x=\"age\",\n",
    "            y=\"bmi\",\n",
    "            color=\"diabetes\",\n",
    "            labels={\"diabetes\": \"Diabetes Class\"},\n",
    "            title=\"BMI vs Age Colored by Diabetes Risk\",\n",
    "        )\n",
    "        st.plotly_chart(fig_bmi_age, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\n",
    "            \"‚ö†Ô∏è Could not plot BMI vs Age: missing 'bmi', 'age' or 'diabetes' column.\"\n",
    "        )\n",
    "\n",
    "    st.markdown(\"#### üß¨ PCA: Patient Clusters\")\n",
    "    # PCA\n",
    "    numeric_df = base_df.select_dtypes(include=\"number\").dropna()\n",
    "    if \"diabetes\" in base_df.columns and not numeric_df.empty:\n",
    "        scaler = StandardScaler()\n",
    "        scaled = scaler.fit_transform(numeric_df)\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced = pca.fit_transform(scaled)\n",
    "        reduced_df = pd.DataFrame(reduced, columns=[\"PC1\", \"PC2\"])\n",
    "        reduced_df[\"diabetes\"] = base_df.loc[numeric_df.index, \"diabetes\"].values\n",
    "\n",
    "        fig_pca = px.scatter(\n",
    "            reduced_df,\n",
    "            x=\"PC1\",\n",
    "            y=\"PC2\",\n",
    "            color=\"diabetes\",\n",
    "            title=\"PCA Projection of Patient Features\",\n",
    "        )\n",
    "        st.plotly_chart(fig_pca, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"‚ö†Ô∏è Cannot show PCA plot because required data is missing.\")\n",
    "\n",
    "    st.markdown(\"#### Feature Distributions by Risk Class\")\n",
    "    if \"Class\" in base_df_o.columns:\n",
    "        feature_options = [\n",
    "            col for col in [\"Frequency\", \"Monetary\", \"Time\"] if col in base_df_o.columns\n",
    "        ]\n",
    "\n",
    "        if feature_options:\n",
    "            feat = st.selectbox(\"Choose a feature:\", feature_options)\n",
    "            fig_box = px.box(\n",
    "                base_df_o,\n",
    "                x=\"Class\",\n",
    "                y=feat,\n",
    "                color=\"Class\",\n",
    "                title=f\"{feat} Distribution by Risk Class\",\n",
    "            )\n",
    "            st.plotly_chart(fig_box, use_container_width=True)\n",
    "        else:\n",
    "            st.info(\"No suitable features available for distribution analysis\")\n",
    "    else:\n",
    "        st.warning(\"'Class' column missing for distribution analysis\")\n",
    "\n",
    "    st.markdown(\"#### Model Evaluation Report\")\n",
    "    # Check for required columns including 'Class'\n",
    "    # required_cols = ]\n",
    "    if all(\n",
    "        col in base_df_o.columns for col in [\"Frequency\", \"Monetary\", \"Time\", \"Class\"]\n",
    "    ):\n",
    "        try:\n",
    "            X = base_df_o[[\"Frequency\", \"Monetary\", \"Time\"]]\n",
    "            y_true = base_df_o[\"Class\"]\n",
    "            y_pred = model.predict(X)\n",
    "\n",
    "            st.text(\"Classification Report:\")\n",
    "            report = classification_report(y_true, y_pred)\n",
    "            st.text(report)\n",
    "        except Exception as e:\n",
    "            st.warning(f\"Could not compute model evaluation metrics: {e}\")\n",
    "    else:\n",
    "        st.warning(\"Required columns for evaluation missing in dataset\")\n",
    "\n",
    "    st.markdown(\"#### Confusion Matrix\")\n",
    "    if y_true is not None and y_pred is not None:\n",
    "        try:\n",
    "            conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "            fig_conf = px.imshow(\n",
    "                conf_matrix,\n",
    "                text_auto=True,\n",
    "                title=\"Confusion Matrix\",\n",
    "                labels=dict(x=\"Predicted\", y=\"Actual\"),\n",
    "            )\n",
    "            st.plotly_chart(fig_conf, use_container_width=True)\n",
    "        except Exception as e:\n",
    "            st.warning(f\"Could not render confusion matrix: {e}\")\n",
    "    else:\n",
    "        st.warning(\"Confusion matrix unavailable - evaluation data missing\")\n",
    "\n",
    "# === Tab 4: AI Chat Assistant ===\n",
    "with tab4:\n",
    "    st.subheader(\"ü§ñ Jake's Chat Assistant\")\n",
    "    st.markdown(\n",
    "        \"Ask personalized health questions and get dynamic responses from Jake AI.\"\n",
    "    )\n",
    "\n",
    "    user_input = st.text_area(\"üí¨ Enter your question:\")\n",
    "    if st.button(\"üöÄ Ask Jake AI\"):\n",
    "        if not user_input.strip():\n",
    "            st.warning(\"‚ö†Ô∏è Please enter a question before submitting.\")\n",
    "        else:\n",
    "            with st.spinner(\"Jake is thinking...\"):\n",
    "                try:\n",
    "                    chat_model = genai.GenerativeModel(\n",
    "                        \"gemini-1.5-flash-latest\")\n",
    "                    chat = chat_model.start_chat(history=[])\n",
    "                    context = st.session_state.get(\"health_summary\", \"\")\n",
    "                    prompt = f\"{context}\\n\\nPatient's Question: {user_input.strip()}\"\n",
    "                    response = chat.send_message(prompt)\n",
    "                    st.markdown(response.text or \"\")\n",
    "                except Exception as e:\n",
    "                    st.error(\"‚ùå Jake AI failed to process the question.\")\n",
    "                    st.exception(e)\n",
    "\n",
    "# === Tab 5: About ===\n",
    "with tab5:\n",
    "    st.subheader(\"‚ÑπÔ∏è About This App\")\n",
    "    st.markdown(\"\"\"\n",
    "    A cutting-edge healthcare recommendation system combining:\n",
    "    - üß† Machine Learning (Logistic Regression)\n",
    "    - üí¨ Jake AI (Gemini)\n",
    "    - üìä Interactive Dashboards\n",
    "    - üìÑ SHAP Explainability + PDF Export\n",
    "\n",
    "    **Developed by:** Jayanth | Full Stack Developer & AI Enthusiast\n",
    "    üîó [GitHub Repository](https://github.com/Jayanth2323/HealthCare)\n",
    "    \"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
